{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aa6151-27bc-4902-9081-3757155a593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results.\n",
    "\n",
    "ANS-1\n",
    "\n",
    "\n",
    "ANOVA (Analysis of Variance) is a statistical test used to compare the means of three or more groups to determine if there are significant differences between them. However, ANOVA relies on certain assumptions to be valid. Violations of these assumptions can impact the validity of the results and may lead to incorrect conclusions.\n",
    "\n",
    "Assumptions for ANOVA:\n",
    "\n",
    "1. **Independence**: Observations within each group are independent of each other. This means that the data points in one group should not be related or influenced by the data points in other groups.\n",
    "\n",
    "2. **Normality**: The distribution of the dependent variable (the outcome being measured) should be approximately normal within each group. This means that the data should follow a bell-shaped curve, and the mean, median, and mode should be close to each other.\n",
    "\n",
    "3. **Homogeneity of Variance (Homoscedasticity)**: The variance of the dependent variable should be approximately equal across all groups. This means that the spread of data points around the mean should be similar for each group.\n",
    "\n",
    "4. **Random Sampling**: The data should be obtained through a random sampling process to ensure that the results can be generalized to the population.\n",
    "\n",
    "Examples of Violations and their Impact:\n",
    "\n",
    "1. **Non-Independence**: If observations within groups are not independent, it can lead to biased results. For example, if measurements are taken from the same subject over time, the repeated measurements within a subject may be correlated, violating the independence assumption.\n",
    "\n",
    "2. **Non-Normality**: If the data are not normally distributed within each group, the results of ANOVA may be affected. Skewed or heavily tailed distributions can lead to inaccurate p-values and confidence intervals. For example, if the data are highly skewed, it may be more appropriate to use a non-parametric test instead of ANOVA.\n",
    "\n",
    "3. **Heteroscedasticity**: When the variance of the dependent variable is not equal across groups, it can affect the reliability of ANOVA results. Unequal variances can lead to incorrect conclusions about the significance of differences between group means. To address heteroscedasticity, transformation of the data or using alternative tests may be necessary.\n",
    "\n",
    "4. **Non-Random Sampling**: If the data are not obtained through a random sampling process, it may limit the generalizability of the results to the target population. For example, if participants are selectively recruited, the results may not be applicable to the broader population.\n",
    "\n",
    "It is essential to assess and address these assumptions before interpreting the results of ANOVA. If assumptions are violated, applying appropriate data transformations or using alternative statistical tests (e.g., non-parametric tests) may be necessary to ensure the validity of the analysis.\n",
    "\n",
    "\n",
    "\n",
    "Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "\n",
    "\n",
    "ANS-2\n",
    "\n",
    "The three types of ANOVA are:\n",
    "\n",
    "1. **One-Way ANOVA**: One-Way ANOVA is used when you have one categorical independent variable (factor) and one continuous dependent variable. It is used to compare means across three or more groups to determine if there are any statistically significant differences between the groups. One-Way ANOVA is appropriate when you have a single factor that divides the data into distinct groups, and you want to test whether there are any significant differences in the means of the dependent variable among these groups.\n",
    "\n",
    "Example: A researcher wants to compare the test scores of students from three different schools to see if there are any significant differences in academic performance.\n",
    "\n",
    "2. **Two-Way ANOVA**: Two-Way ANOVA is used when you have two categorical independent variables (factors) and one continuous dependent variable. It is an extension of One-Way ANOVA and allows you to investigate the interaction between the two factors in addition to testing the main effects of each factor. Two-Way ANOVA is suitable when you have two factors that can influence the dependent variable, and you want to examine the effects of each factor independently as well as their combined effect.\n",
    "\n",
    "Example: A researcher wants to investigate the effect of two different treatments (factor 1) and gender (factor 2) on patients' recovery time from a certain illness.\n",
    "\n",
    "3. **Repeated Measures ANOVA**: Repeated Measures ANOVA is used when you have one categorical independent variable (factor) and one continuous dependent variable, but the measurements are taken from the same subjects at different time points or under different conditions. It is used to analyze within-subjects or repeated measures designs. Repeated Measures ANOVA is appropriate when you want to test whether there are significant differences in the means of the dependent variable across different time points or conditions within the same subjects.\n",
    "\n",
    "Example: A researcher measures the heart rate of participants before, during, and after they perform a physical exercise to see if there are any significant changes in heart rate over time.\n",
    "\n",
    "In summary, the choice of which type of ANOVA to use depends on the number of factors and whether the measurements are taken from the same subjects at different time points or under different conditions. One-Way ANOVA is used when there is one factor, Two-Way ANOVA is used when there are two factors, and Repeated Measures ANOVA is used when measurements are taken from the same subjects repeatedly.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "\n",
    "\n",
    "ANS-3\n",
    "\n",
    "\n",
    "The partitioning of variance in ANOVA refers to the division of the total variance observed in the data into different components, each associated with a specific source of variation. These components are typically attributed to different factors or effects that are being tested in the ANOVA. Understanding the concept of partitioning of variance is crucial because it provides valuable insights into how much of the total variance in the data can be attributed to the factors being studied and how much is due to random variability or error.\n",
    "\n",
    "In ANOVA, the total variance in the data is divided into three main components:\n",
    "\n",
    "1. **Between-Group Variance (Treatment Variance)**: This component of variance represents the differences between the group means. It measures the variability between the groups caused by the effects of the independent variable (factor) being studied. In other words, it quantifies how much of the variation in the dependent variable can be attributed to the different levels of the independent variable.\n",
    "\n",
    "2. **Within-Group Variance (Error Variance)**: This component of variance represents the variability within each group. It measures the random variability or error in the data that cannot be explained by the effects of the independent variable. It includes individual differences, measurement errors, and other sources of random variation.\n",
    "\n",
    "3. **Total Variance**: This is the overall variability in the data, and it is the sum of the between-group variance and the within-group variance. It represents the total variation in the dependent variable without considering any specific factors or effects.\n",
    "\n",
    "The partitioning of variance is represented by the following equation:\n",
    "\n",
    "\\[ \\text{Total Variance} = \\text{Between-Group Variance} + \\text{Within-Group Variance} \\]\n",
    "\n",
    "The F-ratio, obtained from the ANOVA test, is the ratio of the between-group variance to the within-group variance. It measures the extent to which the group means differ significantly from what would be expected due to random variation alone. By comparing the F-ratio to the critical value from the F-distribution, we can determine whether there are statistically significant differences between the group means.\n",
    "\n",
    "Understanding the partitioning of variance is essential because it helps researchers assess the impact of different factors on the dependent variable. It allows us to determine whether the effects of the independent variable(s) are strong enough to account for a significant portion of the variability in the data and whether any observed differences between groups are likely due to more than just random chance. Additionally, it provides a clear and structured way to interpret the results of ANOVA and draw meaningful conclusions from the analysis.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "\n",
    "\n",
    "ANS-4\n",
    "\n",
    "\n",
    "In a one-way ANOVA, you can calculate the Total Sum of Squares (SST), Explained Sum of Squares (SSE), and Residual Sum of Squares (SSR) to assess the total variation in the data, the variation explained by the group differences, and the unexplained or error variation, respectively. You can use Python to compute these sums of squares from the data.\n",
    "\n",
    "Assuming you have data organized into different groups, you can calculate these sums of squares as follows:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Sample data for each group (replace with your actual data)\n",
    "group_1 = np.array([data_point_1, data_point_2, ..., data_point_n1])\n",
    "group_2 = np.array([data_point_1, data_point_2, ..., data_point_n2])\n",
    "# Add more groups as needed\n",
    "\n",
    "# Calculate the overall mean\n",
    "overall_mean = np.mean(np.concatenate([group_1, group_2], axis=0))\n",
    "\n",
    "# Calculate the number of observations in each group\n",
    "n1 = len(group_1)\n",
    "n2 = len(group_2)\n",
    "# Add more counts as needed\n",
    "\n",
    "# Calculate the group means\n",
    "group_1_mean = np.mean(group_1)\n",
    "group_2_mean = np.mean(group_2)\n",
    "# Calculate more group means as needed\n",
    "\n",
    "# Calculate the Total Sum of Squares (SST)\n",
    "squared_differences_total = np.sum((np.concatenate([group_1, group_2], axis=0) - overall_mean) ** 2)\n",
    "sst = squared_differences_total\n",
    "\n",
    "# Calculate the Explained Sum of Squares (SSE)\n",
    "squared_differences_group_1 = np.sum((group_1 - group_1_mean) ** 2)\n",
    "squared_differences_group_2 = np.sum((group_2 - group_2_mean) ** 2)\n",
    "# Calculate more squared differences for other groups as needed\n",
    "\n",
    "sse = squared_differences_group_1 + squared_differences_group_2\n",
    "# Add more squared differences for other groups as needed\n",
    "\n",
    "# Calculate the Residual Sum of Squares (SSR)\n",
    "ssr = sst - sse\n",
    "\n",
    "# Display the results\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)\n",
    "```\n",
    "\n",
    "In this code, we first calculate the overall mean of all observations. Then, we calculate the group means for each group. Next, we compute the squared differences for each observation from the overall mean to calculate the Total Sum of Squares (SST). Then, we calculate the squared differences for each observation from its respective group mean to determine the Explained Sum of Squares (SSE). Finally, we obtain the Residual Sum of Squares (SSR) by subtracting SSE from SST.\n",
    "\n",
    "Make sure to replace `group_1`, `group_2`, etc., with the actual data for each group in your analysis.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n",
    "\n",
    "\n",
    "ANS-5\n",
    "\n",
    "\n",
    "In a two-way ANOVA, you can calculate the main effects and interaction effects to assess the influence of each factor and the combined effect of the factors on the dependent variable. To do this in Python, you can use libraries like `statsmodels` or `scipy.stats`.\n",
    "\n",
    "Assuming you have data organized into two categorical independent variables (factors) and one continuous dependent variable, here's how you can calculate the main effects and interaction effects using `statsmodels`:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Assuming you have a DataFrame 'df' with columns for each factor and the dependent variable\n",
    "# 'factor1' and 'factor2' are the column names for the two factors, and 'dependent_var' is the column name for the dependent variable\n",
    "\n",
    "# Create the model formula for two-way ANOVA with interaction\n",
    "formula = f\"{dependent_var} ~ {factor1} * {factor2}\"\n",
    "\n",
    "# Fit the model\n",
    "model = ols(formula, data=df).fit()\n",
    "\n",
    "# Perform ANOVA to obtain the main effects and interaction effects\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Display the ANOVA table\n",
    "print(anova_table)\n",
    "```\n",
    "\n",
    "The `anova_lm` function from `statsmodels` calculates the ANOVA table, which contains information about the main effects and interaction effects. The columns in the ANOVA table represent the main effects of each factor, the interaction effect between the factors, and the residual (error) effect. The rows represent the sums of squares (SS), degrees of freedom (df), mean squares (MS), F-ratios (F), and p-values (PR(>F)) for each effect.\n",
    "\n",
    "To interpret the ANOVA table:\n",
    "\n",
    "- The main effect F-ratios and p-values for each factor assess the significance of each factor's influence on the dependent variable independently.\n",
    "- The interaction effect F-ratio and p-value assess the significance of the combined effect of the two factors on the dependent variable.\n",
    "\n",
    "If the p-value for a main effect or interaction effect is less than your chosen significance level (commonly 0.05), it indicates that the corresponding factor or interaction has a significant effect on the dependent variable. If the p-value is greater than the significance level, it suggests that the effect is not statistically significant.\n",
    "\n",
    "Please note that before running the code, ensure you have installed the required libraries (`statsmodels`, `scipy`, and `pandas`) and replaced the placeholders `df`, `factor1`, `factor2`, and `dependent_var` with the appropriate column names and DataFrame in your dataset.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?\n",
    "\n",
    "\n",
    "ANS-6\n",
    "\n",
    "\n",
    "\n",
    "In a one-way ANOVA, the F-statistic and p-value are used to determine whether there are significant differences between the means of the groups. Let's interpret the results based on the given F-statistic of 5.23 and a p-value of 0.02.\n",
    "\n",
    "1. **F-Statistic**: The F-statistic is a measure of the ratio of the variance between the group means to the variance within the groups. A larger F-statistic indicates that the variability between the group means is more significant compared to the variability within the groups.\n",
    "\n",
    "2. **P-value**: The p-value is the probability of obtaining the observed F-statistic (or a more extreme value) under the assumption that there are no significant differences between the group means. A smaller p-value suggests that the observed differences between the groups are unlikely to be due to random chance alone.\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "With an F-statistic of 5.23 and a p-value of 0.02, we can make the following conclusions:\n",
    "\n",
    "1. **Significant Differences**: The p-value (0.02) is less than the chosen significance level (commonly 0.05), indicating that there are significant differences between the means of the groups. In other words, the observed differences in the sample means are unlikely to have occurred by chance alone.\n",
    "\n",
    "2. **Reject the Null Hypothesis**: In ANOVA, the null hypothesis states that there are no significant differences between the group means. Since the p-value is less than the significance level, we reject the null hypothesis in favor of the alternative hypothesis. The alternative hypothesis is that there are significant differences between the group means.\n",
    "\n",
    "3. **Practical Significance**: While the results are statistically significant, it is also essential to consider whether the observed differences between the groups have practical significance or real-world importance. A statistically significant result does not necessarily imply a large or practically meaningful effect size.\n",
    "\n",
    "In summary, with an F-statistic of 5.23 and a p-value of 0.02, we conclude that there are significant differences between the means of the groups being compared. However, further analysis and consideration of the effect size are needed to assess the practical importance of these differences. If the effect size is small, even though the differences are statistically significant, they may not have substantial practical relevance.\n",
    "\n",
    "\n",
    "\n",
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?\n",
    "\n",
    "\n",
    "ANS-7\n",
    "\n",
    "\n",
    "Handling missing data in a repeated measures ANOVA is essential to ensure the accuracy and validity of the results. Missing data can arise due to various reasons, such as participant dropout, technical issues, or non-response. There are several methods to handle missing data in a repeated measures ANOVA, each with its potential consequences:\n",
    "\n",
    "1. **Complete Case Analysis (Listwise Deletion)**:\n",
    "   - In this approach, any participant with missing data on any variable is removed from the analysis. Only complete cases (participants with data for all time points) are included in the ANOVA.\n",
    "   - Consequence: The main consequence of this method is a reduction in sample size, which can lead to loss of statistical power and potentially biased results if missingness is related to the outcome variable or other factors.\n",
    "\n",
    "2. **Mean Imputation**:\n",
    "   - Missing values are replaced with the mean of the available data for that variable. This approach is often used to \"fill in\" the missing values.\n",
    "   - Consequence: Mean imputation can artificially reduce the variability in the data, leading to underestimation of standard errors and inflated significance levels. It also does not account for uncertainty in the imputed values, potentially leading to biased estimates.\n",
    "\n",
    "3. **Last Observation Carried Forward (LOCF)**:\n",
    "   - Missing values are replaced with the last observed value for that participant. This method is commonly used when the missingness is expected to be temporary or when the variable is thought to be relatively stable over time.\n",
    "   - Consequence: LOCF can lead to an overestimation of the stability of the variable over time, especially if the missing values are not missing at random.\n",
    "\n",
    "4. **Multiple Imputation**:\n",
    "   - Multiple imputation involves creating multiple plausible imputed datasets using statistical models that take into account the relationships between variables. The analysis is then performed separately on each imputed dataset, and the results are combined to produce overall estimates and standard errors.\n",
    "   - Consequence: Multiple imputation is considered one of the most valid methods for handling missing data. However, it can be computationally intensive and may require more complex analyses compared to other methods.\n",
    "\n",
    "5. **Maximum Likelihood Estimation**:\n",
    "   - This method involves estimating the model parameters using the likelihood function, taking into account the observed and missing data. It can be used with missing at random (MAR) assumptions.\n",
    "   - Consequence: Maximum likelihood estimation can provide unbiased parameter estimates if the missing data mechanism is correctly specified. However, the method's accuracy relies on the validity of the missing data assumptions.\n",
    "\n",
    "Choosing the appropriate method to handle missing data in a repeated measures ANOVA depends on the nature and extent of missingness, the underlying missing data mechanism, and the research question. It is essential to consider the potential consequences of each method and to be transparent in reporting the approach used and its potential impact on the results. Additionally, sensitivity analyses can be performed to assess the robustness of the results to different missing data handling strategies.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary.\n",
    "\n",
    "\n",
    "\n",
    "ANS-8\n",
    "\n",
    "\n",
    "\n",
    "After conducting an ANOVA and finding a significant overall effect (i.e., rejecting the null hypothesis that all group means are equal), post-hoc tests are used to compare specific pairs of groups to identify which groups differ significantly from each other. Post-hoc tests help to avoid making type I errors (false positives) when comparing multiple groups, as the family-wise error rate increases with multiple pairwise comparisons.\n",
    "\n",
    "Some common post-hoc tests used after ANOVA include:\n",
    "\n",
    "1. **Tukey's Honestly Significant Difference (HSD)**:\n",
    "   - Tukey's HSD test is conservative and is used when you have a balanced design (equal sample sizes across groups). It controls the family-wise error rate to maintain the overall alpha level.\n",
    "   - Example: In a study comparing the effectiveness of four different treatments on pain relief, ANOVA indicates a significant difference among the treatment groups. To identify which treatments differ significantly from each other, you can use Tukey's HSD test.\n",
    "\n",
    "2. **Bonferroni Correction**:\n",
    "   - The Bonferroni correction is a straightforward method that adjusts the significance level for each comparison to control the family-wise error rate. It is commonly used when the number of pairwise comparisons is small.\n",
    "   - Example: In a study comparing the performance of three different groups in a memory task, ANOVA shows a significant difference among the groups. To conduct pairwise comparisons while controlling for multiple comparisons, you can apply the Bonferroni correction.\n",
    "\n",
    "3. **Dunn's Test**:\n",
    "   - Dunn's test (also known as the Dunn-Bonferroni test) is a non-parametric alternative for post-hoc testing. It is used when the assumption of normality is violated, or the sample sizes are unequal between groups.\n",
    "   - Example: In a study investigating the effects of three different diets on weight loss, ANOVA suggests a significant difference among the diets. To compare the diets in a non-parametric setting, you can use Dunn's test.\n",
    "\n",
    "4. **Scheffe's Method**:\n",
    "   - Scheffe's method is a conservative post-hoc test that can be used when the assumption of homogeneity of variance is violated or when sample sizes are unequal between groups.\n",
    "   - Example: In a study comparing the performance of four different training programs on athletic performance, ANOVA shows a significant difference among the programs. To conduct post-hoc comparisons that account for unequal variances, you can use Scheffe's method.\n",
    "\n",
    "The choice of which post-hoc test to use depends on the specific research question, the design of the study (balanced or unbalanced), the sample sizes, and the distributional properties of the data. The goal is to select a post-hoc test that appropriately controls for the type I error rate while providing meaningful comparisons among the groups.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results.\n",
    "\n",
    "\n",
    "\n",
    "ANS-9\n",
    "\n",
    "\n",
    "\n",
    "To conduct a one-way ANOVA in Python to compare the mean weight loss of three diets (A, B, and C) using the data from 50 participants, we can use the `scipy.stats` module. Let's assume that the weight loss data is stored in a NumPy array or a Pandas DataFrame with a column named 'Weight_Loss' representing the weight loss for each participant and another column named 'Diet' indicating the diet group (A, B, or C).\n",
    "\n",
    "Here's how you can perform the one-way ANOVA:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Assuming you have the weight loss data in a DataFrame 'df' with 'Weight_Loss' and 'Diet' columns\n",
    "# 'Diet' column should have categorical labels (A, B, C) representing the diet groups\n",
    "\n",
    "# Extract weight loss data for each diet group\n",
    "diet_A_data = df[df['Diet'] == 'A']['Weight_Loss']\n",
    "diet_B_data = df[df['Diet'] == 'B']['Weight_Loss']\n",
    "diet_C_data = df[df['Diet'] == 'C']['Weight_Loss']\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A_data, diet_B_data, diet_C_data)\n",
    "\n",
    "# Display the results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "```\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "After running the code, you will obtain the F-statistic and p-value from the one-way ANOVA. The interpretation of the results depends on the obtained p-value:\n",
    "\n",
    "1. If the p-value is less than your chosen significance level (commonly 0.05):\n",
    "   - **Statistical Significance**: You can conclude that there are significant differences between the mean weight loss of the three diets (A, B, and C).\n",
    "   - **Reject the Null Hypothesis**: The null hypothesis for ANOVA assumes that there are no significant differences between the means of the groups. Since the p-value is less than 0.05, you reject the null hypothesis in favor of the alternative hypothesis, indicating that there are significant differences in weight loss between the diets.\n",
    "\n",
    "2. If the p-value is greater than or equal to your chosen significance level (e.g., 0.05):\n",
    "   - **Lack of Statistical Significance**: You would not have sufficient evidence to conclude that there are significant differences between the mean weight loss of the three diets.\n",
    "   - **Fail to Reject the Null Hypothesis**: The results do not provide enough evidence to reject the null hypothesis, indicating that there are no significant differences in weight loss between the diets.\n",
    "\n",
    "In either case, it is essential to remember that the one-way ANOVA only tells you that there are differences between the groups' means, but it does not indicate which specific groups are different from each other. To identify the specific differences, you would need to conduct post-hoc tests, as discussed in a previous response.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ANS-10\n",
    "\n",
    "\n",
    "\n",
    "To conduct a two-way ANOVA in Python to analyze the differences in the average time to complete a task using three different software programs (Program A, Program B, and Program C) based on employee experience level (novice vs. experienced), we can use the `statsmodels` library. Let's assume that the data is stored in a Pandas DataFrame named `df` with columns 'Time', 'Software', and 'Experience', where 'Time' represents the task completion time, 'Software' represents the software program used, and 'Experience' represents the experience level of the employee (novice or experienced).\n",
    "\n",
    "Here's how you can perform the two-way ANOVA:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Assuming you have the data in a DataFrame 'df' with 'Time', 'Software', and 'Experience' columns\n",
    "\n",
    "# Create the model formula for two-way ANOVA with interaction\n",
    "formula = 'Time ~ Software + Experience + Software:Experience'\n",
    "\n",
    "# Fit the model\n",
    "model = ols(formula, data=df).fit()\n",
    "\n",
    "# Perform ANOVA to obtain the main effects and interaction effects\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Display the ANOVA table\n",
    "print(anova_table)\n",
    "```\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "After running the code, you will obtain an ANOVA table with the F-statistics and p-values for the main effects and interaction effect:\n",
    "\n",
    "- **Main Effects**: Look for the 'Software' and 'Experience' rows in the ANOVA table. If the p-values for these factors are less than your chosen significance level (e.g., 0.05), it indicates a significant main effect. A significant main effect means that there is a significant difference in the average task completion time among different software programs or between novice and experienced employees.\n",
    "\n",
    "- **Interaction Effect**: Look for the 'Software:Experience' row in the ANOVA table. If the p-value for this interaction term is less than your chosen significance level, it indicates a significant interaction effect between the software programs and employee experience level. A significant interaction means that the effect of one factor (e.g., software program) on task completion time depends on the level of the other factor (e.g., novice vs. experienced).\n",
    "\n",
    "Interpret the results based on the obtained p-values and the chosen significance level. If a main effect or interaction effect has a p-value less than the significance level, it suggests that the factor has a significant impact on task completion time. Conversely, if a p-value is greater than the significance level, it indicates a lack of statistical significance for that effect.\n",
    "\n",
    "Remember to interpret the results in the context of the specific research question and the practical significance of any significant effects. Additionally, consider conducting post-hoc tests to explore specific group differences if you find significant main effects or interactions.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other.\n",
    "\n",
    "\n",
    "\n",
    "ANS-11\n",
    "\n",
    "\n",
    "\n",
    "To conduct a two-sample t-test in Python to compare the test scores between the control group (traditional teaching method) and the experimental group (new teaching method), and perform a post-hoc test if the results are significant, we can use the `scipy.stats` module. Additionally, if the t-test yields significant results, we can perform a post-hoc test, such as Tukey's HSD, to identify which groups differ significantly from each other.\n",
    "\n",
    "Assuming you have the test scores for the two groups in separate NumPy arrays (e.g., `control_group_scores` and `experimental_group_scores`), here's how you can perform the two-sample t-test and the post-hoc test:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "# Assuming you have the test scores for the control and experimental groups in separate NumPy arrays\n",
    "control_group_scores = np.array([score1, score2, ..., score_n_control])\n",
    "experimental_group_scores = np.array([score1, score2, ..., score_n_experimental])\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group_scores, experimental_group_scores)\n",
    "\n",
    "# Display the t-statistic and p-value from the t-test\n",
    "print(\"Two-sample t-test - t-statistic:\", t_statistic)\n",
    "print(\"Two-sample t-test - p-value:\", p_value)\n",
    "\n",
    "# Perform post-hoc test (Tukey's HSD) if the t-test is significant (p-value < 0.05)\n",
    "if p_value < 0.05:\n",
    "    # Combine the data for the post-hoc test\n",
    "    all_scores = np.concatenate([control_group_scores, experimental_group_scores])\n",
    "    all_groups = np.concatenate([np.repeat('Control', len(control_group_scores)),\n",
    "                                 np.repeat('Experimental', len(experimental_group_scores))])\n",
    "\n",
    "    # Create a MultiComparison object for post-hoc test (Tukey's HSD)\n",
    "    posthoc = MultiComparison(all_scores, all_groups)\n",
    "\n",
    "    # Perform the post-hoc test and obtain the results\n",
    "    posthoc_result = posthoc.tukeyhsd()\n",
    "\n",
    "    # Display the post-hoc test results\n",
    "    print(\"\\nPost-hoc test (Tukey's HSD):\")\n",
    "    print(posthoc_result)\n",
    "```\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "1. **Two-Sample t-test**: After running the code, you will obtain the t-statistic and p-value from the two-sample t-test. If the p-value is less than your chosen significance level (e.g., 0.05), it indicates a significant difference in test scores between the control and experimental groups.\n",
    "\n",
    "2. **Post-hoc Test**: If the t-test is significant (p-value < 0.05), you can perform the post-hoc test (Tukey's HSD) to identify which groups (control or experimental) differ significantly from each other. The post-hoc test results will provide confidence intervals and p-values for all pairwise group comparisons, helping you identify significant differences among the groups.\n",
    "\n",
    "Interpret the post-hoc test results carefully to identify which group(s) have significantly different test scores. Keep in mind that the significance level for the post-hoc test is adjusted for multiple comparisons to control the family-wise error rate. Therefore, you can trust the results for pairwise group comparisons with p-values less than the adjusted significance level (e.g., 0.05). Any significant differences found through the post-hoc test should be reported and interpreted in the context of the research question and the practical implications of the teaching method's effectiveness.\n",
    "                                                                                                        \n",
    "                                                                                                        \n",
    "                                                                                                        \n",
    "                                                                                                        \n",
    "                                                                                                        \n",
    "                                                                                                        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
